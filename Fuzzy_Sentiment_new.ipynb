{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15809b2b"
      },
      "outputs": [],
      "source": [
        "# utilities\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# plotting\n",
        "# import seaborn as sns\n",
        "# from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "!pip install nltk\n",
        "!pip install tensorflow\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')"
      ],
      "id": "15809b2b"
    },
    {
      "cell_type": "code",
      "source": [
        "csv_data=csv_data = pd.read_csv('extended_googleplaystore_user_reviews.csv',error_bad_lines=False)\n",
        "print(csv_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24LufFvLveKW",
        "outputId": "2c576d8e-f792-4f8e-928c-9af7f0645533"
      },
      "id": "24LufFvLveKW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     App                                  Translated_Review  \\\n",
            "0  10 Best Foods for You  I like eat delicious food. That's I'm cooking ...   \n",
            "1  10 Best Foods for You    This help eating healthy exercise regular basis   \n",
            "2  10 Best Foods for You                                                NaN   \n",
            "3  10 Best Foods for You         Works great especially going grocery store   \n",
            "4  10 Best Foods for You                                       Best idea us   \n",
            "\n",
            "   sentences_count  characters_count  spaces_count  count_words  \\\n",
            "0              2.0             122.0          20.0         22.0   \n",
            "1              1.0              47.0           6.0          7.0   \n",
            "2              NaN               NaN           NaN          NaN   \n",
            "3              1.0              42.0           5.0          6.0   \n",
            "4              1.0              12.0           2.0          3.0   \n",
            "\n",
            "   duplicates_count  chars_excl_spaces_count  emoji_count  \\\n",
            "0               6.0                    102.0          0.0   \n",
            "1               0.0                     41.0          0.0   \n",
            "2               NaN                      NaN          NaN   \n",
            "3               0.0                     37.0          0.0   \n",
            "4               0.0                     10.0          0.0   \n",
            "\n",
            "   whole_numbers_count  ...  spelling_quality  spelling_quality_summarised  \\\n",
            "0                  1.0  ...               Bad                          Bad   \n",
            "1                  0.0  ...         Very good                         Good   \n",
            "2                  NaN  ...               NaN                          NaN   \n",
            "3                  0.0  ...         Very good                         Good   \n",
            "4                  0.0  ...         Very good                         Good   \n",
            "\n",
            "   ease_of_reading_score  ease_of_reading_quality  ease_of_reading_summarised  \\\n",
            "0                  86.20                     Easy                        Easy   \n",
            "1                  38.99                Difficult                   Difficult   \n",
            "2                    NaN                      NaN                         NaN   \n",
            "3                  48.47                Difficult                   Difficult   \n",
            "4                 119.19                Very Easy                        Easy   \n",
            "\n",
            "   grammar_check_score  grammar_check original_Sentiment  \\\n",
            "0                  5.0       5 issues           Positive   \n",
            "1                  0.0      No issues           Positive   \n",
            "2                  NaN            NaN                NaN   \n",
            "3                  0.0      No issues           Positive   \n",
            "4                  1.0        1 issue           Positive   \n",
            "\n",
            "  original_Sentiment_Polarity  original_Sentiment_Subjectivity  \n",
            "0                        1.00                         0.533333  \n",
            "1                        0.25                         0.288462  \n",
            "2                         NaN                              NaN  \n",
            "3                        0.40                         0.875000  \n",
            "4                        1.00                         0.300000  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e405d43d1683>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  csv_data=csv_data = pd.read_csv('extended_googleplaystore_user_reviews.csv',error_bad_lines=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a9fb1b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d1471c-220e-4f35-e610-6ca593dab010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 -1.0 4884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b9ab68f82e6c>:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  csv_data = pd.read_csv('extended_googleplaystore_user_reviews.csv',error_bad_lines=False)\n"
          ]
        }
      ],
      "source": [
        "# Data Preparation\n",
        "csv_data = pd.read_csv('extended_googleplaystore_user_reviews.csv',error_bad_lines=False)\n",
        "csv_data = csv_data[csv_data['Translated_Review'].notna()]\n",
        "p=csv_data['original_Sentiment_Polarity'].max()\n",
        "q=csv_data['original_Sentiment_Polarity'].min()\n",
        "\n",
        "print(p,q,len(csv_data))\n"
      ],
      "id": "5a9fb1b7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c69cdcfe"
      },
      "outputs": [],
      "source": [
        "class SentimentSatisfaction:\n",
        "    def __init__(self,satisfaction_index):\n",
        "        self.satisfaction_index = satisfaction_index\n",
        "    def get_sentiment_satisfaction(self):\n",
        "        if self.satisfaction_index <= -0.6:\n",
        "            return 0\n",
        "        elif self.satisfaction_index <= -0.2:\n",
        "            return 1\n",
        "        elif self.satisfaction_index <= 0.2:\n",
        "            return 2\n",
        "        elif self.satisfaction_index <= 0.6:\n",
        "            return 3\n",
        "        else:\n",
        "            return 4\n",
        "\n",
        "satisfaction_class = {\n",
        "    \"very_negative\":0,\n",
        "    \"negative\":1,\n",
        "    \"neutral\":2,\n",
        "    \"positive\":3,\n",
        "    \"very_positive\":4\n",
        "    }\n",
        "csv_data['result'] = csv_data['original_Sentiment_Polarity'].apply(lambda x:SentimentSatisfaction(x).get_sentiment_satisfaction())"
      ],
      "id": "c69cdcfe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "068a1476"
      },
      "outputs": [],
      "source": [
        "data = csv_data.copy()\n",
        "data = csv_data[['Translated_Review','result','original_Sentiment_Polarity']]"
      ],
      "id": "068a1476"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d78a0e5"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------------------------------------------------------------\n",
        "# Cleaning and Wrangling of Data\n",
        "#-------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Remove URLs and mentions from text\n",
        "data.loc[:,'Translated_Review'] = data['Translated_Review'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "data.loc[:,'Translated_Review'] = data['Translated_Review'].apply(lambda x: re.sub(r'@\\S+', '', x))\n",
        "\n",
        "\n",
        "\n",
        "# Remove non-alphabetic characters and convert to lowercase\n",
        "data.loc[:,'Translated_Review'] = data['Translated_Review'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x.lower()))\n",
        "\n",
        "# Tokenize text\n",
        "data.loc[:,'Translated_Review'] = data['Translated_Review'].apply(lambda x: nltk.word_tokenize(x))\n",
        "data.loc[:,'Translated_Review'] = data['Translated_Review'].apply(lambda x: [value for value in x if not re.match(r'^-?\\d+\\.?\\d*$', value)])\n",
        "\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "data.loc[:,'Translated_Review'] = data['Translated_Review'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "\n",
        "# Lemmatize text\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "data.loc[:,'Translated_Review'] = data['Translated_Review'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "\n",
        "# Join tokens back into strings\n",
        "data.loc[:,'Translated_Review'] = data['Translated_Review'].apply(lambda x: ' '.join(x))\n",
        "data.head()"
      ],
      "id": "0d78a0e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44255d7b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# For Machine Learning\n",
        "m_data = data.copy()\n",
        "review_data = m_data['Translated_Review']\n",
        "result_data = m_data['result']\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the data using the vectorizer object\n",
        "c_vectorized_data = vectorizer.fit_transform(review_data)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(c_vectorized_data, result_data, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "id": "44255d7b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression model\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_preds = lr_model.predict(X_test)\n",
        "print('Logistic Regression Accuracy:', accuracy_score(y_test, lr_preds))\n",
        "\n",
        "# Support Vector Machine model\n",
        "svm_model = SVC(probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_preds = svm_model.predict(X_test)\n",
        "print('SVM Accuracy:', accuracy_score(y_test, svm_preds))\n",
        "\n",
        "# BiLSTM model\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(review_data)\n",
        "sequences = tokenizer.texts_to_sequences(review_data)\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
        "bi_model = Sequential()\n",
        "bi_model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=max_length))\n",
        "bi_model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "bi_model.add(Dense(64, activation='relu'))\n",
        "bi_model.add(Dropout(0.5))\n",
        "bi_model.add(Dense(5, activation='softmax'))\n",
        "bi_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "bi_model.fit(padded_sequences, np.array(result_data), epochs=10, batch_size=32, validation_split=0.2)\n",
        "bi_preds = bi_model.predict_classes(X_test)\n",
        "print('BiLSTM Accuracy:', accuracy_score(y_test, bi_preds))\n",
        "\n",
        "# Create the VotingClassifier\n",
        "voting_clf = VotingClassifier(estimators=[('logreg', lr_model), ('svm', svm_model), ('bilstm', bi_model)], voting='soft')\n",
        "voting_clf.fit(X_train, y_train)\n",
        "voting_preds = voting_clf.predict(X_test)\n",
        "voting_accuracy = accuracy_score(y_test, voting_preds)\n",
        "print('Voting Classifier Accuracy:', voting_accuracy)\n",
        "\n",
        "# Final voting_lg_bilstm prediction\n",
        "voting_lg_bilstm = voting_clf.predict(c_vectorized_data)\n",
        "voting_lg_bilstm_accuracy = accuracy_score(result_data, voting_lg_bilstm)\n",
        "print('Voting LG BiLSTM Accuracy:', voting_lg_bilstm_accuracy)\n",
        "\n",
        "# Create the VotingClassifier with BiLSTM and Hyperparameters\n",
        "voting_clf_hp = VotingClassifier(estimators=[('bilstm', bi_model), ('voting_clf', voting_clf)], voting='hard')\n",
        "voting_clf_hp.fit(X_train, y_train)\n",
        "voting_lg_bilstm_hp = voting_clf_hp.predict(c_vectorized_data)\n",
        "voting_lg_bilstm_hp_accuracy = accuracy_score(result_data, voting_lg_bilstm_hp)\n",
        "print('Voting LG BiLSTM with Hyperparameters Accuracy:', voting_lg_bilstm_hp_accuracy)\n"
      ],
      "metadata": {
        "id": "zQt4-wusj5H9"
      },
      "id": "zQt4-wusj5H9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s-GgIZpomMX"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression model\n",
        "lr_model1 = LogisticRegression()\n",
        "\n",
        "# Train logistic regression models\n",
        "lr_model1.fit(X_train, y_train)\n",
        "\n",
        "# Logistic Regression predictions\n",
        "lr_preds1 = lr_model1.predict(X_test)\n",
        "print('Accuracy',accuracy_score(y_test,lr_preds1))"
      ],
      "id": "5s-GgIZpomMX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biH_wxfS4_Ie"
      },
      "outputs": [],
      "source": [
        "svm_model = SVC(probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "print('Accuracy',accuracy_score(y_test,svm_pred))"
      ],
      "id": "biH_wxfS4_Ie"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo0vrlO86yqk"
      },
      "outputs": [],
      "source": [
        "voting_clf = VotingClassifier(estimators=[('logreg', lr_model1), ('svm', svm_model)], voting='soft')\n",
        "voting_clf.fit(X_train, y_train)\n",
        "voting_pred = voting_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, voting_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "id": "Uo0vrlO86yqk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c87ecdd8"
      },
      "outputs": [],
      "source": [
        "# Plot the accuracies\n",
        "labels = ['Logistic Regression', 'Support Vector Machine','Voting LR and SVM']\n",
        "accuracies = [accuracy_score(y_test,lr_preds1), accuracy_score(y_test,svm_pred),accuracy_score(y_test, voting_pred)]\n",
        "\n",
        "plt.bar(labels, accuracies)\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of Logistic Regression, SVM and Ensembled')\n",
        "# Add accuracy points above each data point\n",
        "for label, accuracy in zip(labels, accuracies):\n",
        "    plt.annotate(f'{accuracy:.2f}', (label, accuracy), textcoords=\"offset points\", xytext=(0, 10), ha='center')\n",
        "\n",
        "plt.show()"
      ],
      "id": "c87ecdd8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45ef18fe"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression and Count Vectorizer\n",
        "# Split the dataset into training and testing sets\n",
        "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(c_vectorized_data, result_data, test_size=0.2,random_state=42)\n",
        "\n",
        "# Train a machine learning model on the training set\n",
        "lr_model_hp = LogisticRegression()\n",
        "\n",
        "# For HyperParameter Tuning\n",
        "param_grid={\n",
        "    'warm_start': [True], \n",
        "    'solver': ['sag'], \n",
        "    'penalty': ['l2'], \n",
        "    'max_iter': [200], \n",
        "    'C': [206.913808111479]\n",
        "}\n",
        "\n",
        "# Perform random search with cross-validation\n",
        "grid_search = GridSearchCV(lr_model_hp, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train_lr, y_train_lr)\n",
        "\n",
        "# Get the best hyperparameters and model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Use the best model to make predictions\n",
        "y_pred_lr = best_model.predict(X_test_lr)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test_lr, y_pred_lr)\n",
        "\n",
        "# For Plot\n",
        "results = grid_search.cv_results_\n",
        "params = results['params']\n",
        "mean_test_scores = results['mean_test_score']\n",
        "# Evaluate the accuracy of the model\n",
        "# Plot the accuracy scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(len(params)), mean_test_scores, align='center', alpha=0.8)\n",
        "plt.xticks(range(len(params)), [str(p) for p in params], rotation='vertical')\n",
        "plt.xlabel('Hyperparameters')\n",
        "plt.ylabel('Mean Test Score')\n",
        "plt.title('GridSearchCV Results - Logistic Regression')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "id": "45ef18fe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o_UCgBeoOS3"
      },
      "outputs": [],
      "source": [
        "voting_clf_hp = VotingClassifier(estimators=[('grid_lr', grid_search), ('svm', svm_model)], voting='hard')\n",
        "voting_clf_hp.fit(X_train, y_train)\n",
        "voting_pred_hp = voting_clf.predict(X_test)\n",
        "print(\"Accuracy with HP:\", accuracy_score(y_test, voting_pred_hp))"
      ],
      "id": "8o_UCgBeoOS3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracies\n",
        "labels = ['Logistic Regression ', 'Ensemble LR HP and SVM']\n",
        "accuracies = [accuracy, accuracy_score(y_test, voting_pred_hp)]\n",
        "\n",
        "plt.bar(labels, accuracies)\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of Logistic Regression HP, SVM and Ensembled')\n",
        "# Add accuracy points above each data point\n",
        "for label, accuracy in zip(labels, accuracies):\n",
        "    plt.annotate(f'{accuracy:.2f}', (label, accuracy), textcoords=\"offset points\", xytext=(0, 10), ha='center')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Oi4Z0GBS-hWV"
      },
      "id": "Oi4Z0GBS-hWV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80127478"
      },
      "outputs": [],
      "source": [
        "# For Deep Learning\n",
        "d_data = data.copy()\n",
        "d_data = d_data[['Translated_Review','result']]\n",
        "texts = d_data['Translated_Review']\n",
        "sentiment = d_data['result']\n",
        "\n",
        "# Tokenize the texts\n",
        "tokenizer = Tokenizer(num_words=17599)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Pad sequences to have the same length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=300)\n",
        "max_len = max(len(sequence) for sequence in sequences)\n"
      ],
      "id": "80127478"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39b57952"
      },
      "outputs": [],
      "source": [
        "X_train_bi, X_test_bi, y_train_bi, y_test_bi = train_test_split(padded_sequences, sentiment, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the BiLSTM model\n",
        "bi_model = Sequential()\n",
        "bi_model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_len))\n",
        "bi_model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "bi_model.add(Bidirectional(LSTM(64)))\n",
        "bi_model.add(Dense(64, activation='relu'))\n",
        "bi_model.add(Dense(5, activation='softmax'))  # 5 classes for fuzzy sentiment analysis\n",
        "\n",
        "# Compile the bi_model\n",
        "bi_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the bi_model\n",
        "history = bi_model.fit(X_train_bi, y_train_bi, validation_data=(X_test_bi, y_test_bi), epochs=10, batch_size=32)\n",
        "\n",
        "accuracy = history.history.get('accuracy')\n",
        "val_acc = history.history.get('val_accuracy')\n",
        "loss = history.history.get('loss')\n",
        "val_loss = history.history.get('val_loss')\n",
        "\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training Acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Acc')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "39b57952"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d79a7c6f"
      },
      "outputs": [],
      "source": [
        "# For Polarity Score Estimation\n",
        "p_data = data.copy()\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sentiment_scores = []\n",
        "for review in p_data['Translated_Review']:\n",
        "    scores = sia.polarity_scores(review)\n",
        "    sentiment_scores.append(scores['compound'])\n",
        "p_data['sentiment_score'] = sentiment_scores\n",
        "# p_data['predicted_label'] = p_data['sentiment_score'].apply(lambda x:SentimentSatisfaction(x).get_sentiment_satisfaction())\n",
        "p_data['predicted_label'] = np.argmax(p_data['sentiment_score'])\n",
        "accuracy = accuracy_score(p_data['result'], p_data['predicted_label'])\n",
        "print(p_data)\n"
      ],
      "id": "d79a7c6f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNBy2NV4n9l9"
      },
      "outputs": [],
      "source": [
        "voting_lg_bilstm = VotingClassifier(estimators=[('bilstm', bi_model), ('voting_clf_hp', voting_clf_hp)], voting='soft')\n",
        "voting_lg_bilstm.fit(X_train_bi, y_train_bi)\n",
        "voting_pred = voting_lg_bilstm.predict(X_test_bi)\n",
        "accuracy = accuracy_score(y_test, voting_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "id": "kNBy2NV4n9l9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph Plot"
      ],
      "metadata": {
        "id": "7YIgoOVkHW7K"
      },
      "id": "7YIgoOVkHW7K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkO2gUNt3QVv"
      },
      "outputs": [],
      "source": [
        "# Custom transformer to extract sentiment scores using SentimentIntensityAnalyzer\n",
        "class SentimentIntensityTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.sid = SentimentIntensityAnalyzer()\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        scores = []\n",
        "        for text in X:\n",
        "            sentiment_scores = self.sid.polarity_scores(text)\n",
        "            scores.append(list(sentiment_scores.values()))\n",
        "        return scores"
      ],
      "id": "QkO2gUNt3QVv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbuGOvP13m5v"
      },
      "outputs": [],
      "source": [
        "# Instantiate the models\n",
        "sid_transformer = SentimentIntensityTransformer()\n",
        "\n",
        "# Define the voting classifier\n",
        "voting_final = VotingClassifier(estimators=[\n",
        "    ('sid', sid_transformer),\n",
        "    ('voting_lg_bilstm', voting_lg_bilstm)\n",
        "], voting='soft')\n",
        "\n",
        "voting_pred_final = voting_lg_bilstm.predict(X_test_bi)\n",
        "accuracy = accuracy_score(y_test, voting_pred_final)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "id": "NbuGOvP13m5v"
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph Plot"
      ],
      "metadata": {
        "id": "Ywg7VJJmHZHP"
      },
      "id": "Ywg7VJJmHZHP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}